<!DOCTYPE html><html lang="en" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png"><link rel="icon" href="/img/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="Bill Hu"><meta name="keywords" content=""><meta name="description" content="My Lecture notes for Intro to Operating Systems, Spring 2023, at UW-Madison"><meta property="og:type" content="article"><meta property="og:title" content="[Lecture Notes] UW-Madison CS537 Operating Systems"><meta property="og:url" content="https://www.billhu.us/2023/37_cs537/index.html"><meta property="og:site_name" content="Bill Hu&#39;s Blog"><meta property="og:description" content="My Lecture notes for Intro to Operating Systems, Spring 2023, at UW-Madison"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/dispatcher.jpg"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/process-3-states.jpg"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/locality.jpeg"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/blockwhenwaiting.png"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/fixed-blockedwhenwaiting.png"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/cv-thread-join.png"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/raid-comparison.png"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/fs-structs.png"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/fs-contiguous-allocation.png"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/fs-small-fixed-num-extents.png"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/fs-linked-allocation.png"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/fs-indexed-allocation.png"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/fs-multilevel-indexing.png"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/ffs-group.png"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/ffs-policy.png"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/ffs-policy-summary.png"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/fs-consistency-example.png"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/TCP-ack.png"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/rpc.png"><meta property="og:image" content="https://www.billhu.us/2023/37_cs537/nfs.png"><meta property="article:published_time" content="2023-05-10T19:20:41.000Z"><meta property="article:modified_time" content="2025-02-20T19:34:08.615Z"><meta property="article:author" content="Bill Hu"><meta property="article:tag" content="Lecture Notes"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://www.billhu.us/2023/37_cs537/dispatcher.jpg"><title>[Lecture Notes] UW-Madison CS537 Operating Systems - Bill Hu&#39;s Blog</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/KaTeX/0.15.6/katex.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="/css/myfont.css"><link rel="stylesheet" href="/css/jetbrains-mono.css"><script id="fluid-configs">var dntVal,Fluid=window.Fluid||{},CONFIG=(Fluid.ctx=Object.assign({},Fluid.ctx),{hostname:"www.billhu.us",root:"/",version:"1.9.7",typing:{enable:!0,typeSpeed:25,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:3},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1},gtag:null},search_path:"/local-search.xml",include_content_in_search:!0});CONFIG.web_analytics.follow_dnt&&(dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on")))</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><script>!function(t,e,n,c,a,r){t[n]=t[n]||function(){(t[n].q=t[n].q||[]).push(arguments)},(a=e.createElement(c)).async=1,a.src="https://www.clarity.ms/tag/fjnxcr4gva",(r=e.getElementsByTagName(c)[0]).parentNode.insertBefore(a,r)}(window,document,"clarity","script")</script><meta name="google-site-verification" content="IqNfw3GiMxuhw7kYoEdhMJoh3j99KHuGI9bw00hPn2c"><link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Kaushan+Script" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700" rel="stylesheet"><meta name="generator" content="Hexo 7.1.1"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Bill Hu&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/" target="_self"><i class="iconfont icon-home-fill"></i> <span>Home</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/" target="_self"><i class="iconfont icon-archive-fill"></i> <span>Archives</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/" target="_self"><i class="iconfont icon-category-fill"></i> <span>Categories</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/" target="_self"><i class="iconfont icon-tags-fill"></i> <span>Tags</span></a></li><li class="nav-item"><a class="nav-link" href="/about/" target="_self"><i class="iconfont icon-user-fill"></i> <span>About</span></a></li><li class="nav-item"><a class="nav-link" href="https://www.billhu.xyz" target="_self"><i class="iconfont icon-code"></i> <span>Portfolio</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/default.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="[Lecture Notes] UW-Madison CS537 Operating Systems"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-05-10 19:20" pubdate>May 10, 2023 pm</time></span></div><div class="mt-1"></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 id="seo-header">[Lecture Notes] UW-Madison CS537 Operating Systems</h1><div class="markdown-body"><h1 id="lec-2-processes"><a class="markdownIt-Anchor" href="#lec-2-processes"></a> Lec 2. Processes</h1><h2 id="what-is-a-process"><a class="markdownIt-Anchor" href="#what-is-a-process"></a> What is a process</h2><ul><li><strong>Execution stream</strong> (thread of control)</li><li><strong>Process state</strong>: everything code can affect or be affected<ul><li>including: PC, registers, memory, opened files, opened OS resources…</li></ul></li></ul><p><strong>Process VS Program</strong></p><ul><li><p><strong>Program</strong>: static data, code</p><ul><li>global or initialized variables</li></ul></li><li><p><strong>Process</strong>: dynamic instance of code + data</p><ul><li>registers, stack, heap, address space, all memory that is accessible</li></ul></li></ul><p>1 copy of program can have many copies of processes.</p><h2 id="virtualizing-cpu"><a class="markdownIt-Anchor" href="#virtualizing-cpu"></a> Virtualizing CPU</h2><p>Goal: give each process the idea that it is running alone</p><p>How to do: <strong>share resources</strong></p><ul><li>For CPU: <strong>time sharing</strong> (save/restore process state)<ul><li>reason we can do time sharing: small CPU/register state goes to memory</li></ul></li><li>For Memory: <strong>space sharing</strong></li></ul><h2 id="getting-good-performance"><a class="markdownIt-Anchor" href="#getting-good-performance"></a> Getting good performance</h2><p><strong>Direct execution</strong>: run directly on hardware. OS loads program, jumps to <code>main</code>.</p><h3 id="problem"><a class="markdownIt-Anchor" href="#problem"></a> Problem</h3><ul><li>process could do something restricted – access another process or user file</li><li>process could run forever – need to stop + take control</li><li>process could do something slow – I/O… We want to use CPU for something else.</li></ul><h3 id="solution-limited-direct-executionlde"><a class="markdownIt-Anchor" href="#solution-limited-direct-executionlde"></a> Solution: Limited Direct Execution(LDE)</h3><p>Let OS+hardware have some control.</p><h3 id="problem-1-restricted-operations"><a class="markdownIt-Anchor" href="#problem-1-restricted-operations"></a> Problem 1: restricted operations</h3><h3 id="solution-system-calls"><a class="markdownIt-Anchor" href="#solution-system-calls"></a> Solution: System calls</h3><h3 id="solution-hardware-privilege-levels"><a class="markdownIt-Anchor" href="#solution-hardware-privilege-levels"></a> Solution: <strong>hardware privilege levels</strong></h3><p>user processes runs in restricted level (‘unprivileged’ or ‘user mode’)</p><p>OS runs in privileged level (‘kernel level’ or ‘kernel mode’)</p><p><strong>What privileges?</strong></p><ul><li>interact with devices (e.g. keyboard)</li><li>interact with memory permissions (e.g. can access whole memory and control permissions in kernel mode)</li></ul><p><strong>How does a process do IO?</strong></p><p>By <strong>System call</strong>:</p><ul><li>controlled transfer into OS</li><li>change privilege levels</li><li>implemented via <strong>Trap</strong> (to control where to jump)</li></ul><p><strong>How to take CPU away?</strong> (take CPU away from a process / control how long a program can run)</p><p>Mechanism: trap to OS + registers save/restore</p><p>OS dispatch loop:</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs maxima"><span class="hljs-keyword">while</span> (<span class="hljs-number">1</span>) &#123;<br>    run process A <span class="hljs-keyword">for</span> <span class="hljs-built_in">some</span> period<br>    stop A, <span class="hljs-built_in">save</span> <span class="hljs-built_in">context</span><br>    <span class="hljs-built_in">load</span> <span class="hljs-built_in">content</span> of another process B<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>Regain control</strong></p><p>Option 1: <strong>Cooperative multitasking</strong>:</p><ul><li><p>Trust process to relinquish CPU</p><ul><li>automatic on syscall</li><li>extra syscall to <code>yield()</code></li></ul></li><li><p>Benefits: no new OS mechanism</p></li><li><p>Drawbacks: lame programmers; not responsive</p></li></ul><p>Option 2: <strong>Timer-based multitasking</strong></p><ul><li><p>Guarantee OS runs periodically</p></li><li><p>Set an alarm (timer)</p><ul><li>program timer to interrupt every 3ms</li><li>interrupt causes trap + handler, invoke dispatch (dispatch can choose to switch process)</li></ul></li></ul><p><strong>Save state</strong></p><p>what: <strong>register state</strong> (including: GPR, PC, stack, frame(ebp))</p><p>where: <strong>process control block (PCB)</strong> (including: PID, process state, priority, register state, address space)</p><h1 id="lec-3-cpu-scheduling"><a class="markdownIt-Anchor" href="#lec-3-cpu-scheduling"></a> Lec 3. CPU Scheduling</h1><h2 id="dispatcher-switches-between-processes"><a class="markdownIt-Anchor" href="#dispatcher-switches-between-processes"></a> Dispatcher - Switches between processes</h2><ul><li>cooperative multitasking</li><li>preemptive/true multitasking (has a timer)</li></ul><p>saving state - called ‘<strong>context switching</strong>’</p><p>loading state</p><img src="/2023/37_cs537/dispatcher.jpg" srcset="/img/loading.gif" lazyload><p>(During context switching, save process’s register to <strong>PCB</strong>)</p><p>(During system call, save to <strong>kernel stack</strong>)</p><p>(When process is descheduled, it’s moved to READY state)</p><p>fa19mid1</p><p>(The <strong>scheduler</strong> determines the policy for which process should be run when. The <strong>CPU dispatcher</strong> implements the mechanism)</p><p>fa16mid1</p><p>(On a system call trap, the <strong>hardware</strong> looks up the <strong>trap table</strong>. <strong>OS</strong> looks up the address of the system call handler in <strong>system call table</strong>.)</p><p>sp22mid1</p><h2 id="slow-operations"><a class="markdownIt-Anchor" href="#slow-operations"></a> Slow operations</h2><p>I/O operations can take a long time. We should run other processes when one process is doing reading/writing files.</p><p>Idea: track <strong>state</strong> of processes</p><ul><li><strong>Running</strong>: on CPU</li><li><strong>Ready</strong>: can run at any time</li><li><strong>Blocked / Waiting</strong>: Asleep, waiting for I/O.</li></ul><img src="/2023/37_cs537/process-3-states.jpg" srcset="/img/loading.gif" lazyload><p>(When a job is descheduled by scheduler, it’s moved to <strong>READY</strong>)</p><p>(fa19mid1)</p><h2 id="policy"><a class="markdownIt-Anchor" href="#policy"></a> Policy</h2><p><strong>Workload</strong>: set of jobs and tasks: (<strong>arrival time</strong>, <strong>run time</strong>)</p><p><strong>Job</strong>: current execution of a process. Alternates between CPU and IO.</p><p><strong>Scheduler</strong>: decides which ready job to run</p><p><strong>Metric</strong>: measurement of scheduling quality</p><p><strong>Overhead</strong> 是什么? TODO</p><h3 id="metrics"><a class="markdownIt-Anchor" href="#metrics"></a> Metrics</h3><p><strong>Turnaround time</strong> = Completion time - arrival time</p><p><strong>Response time</strong> = First run time - arrival time</p><p><strong>Wait time</strong> = Time not scheduled between arrival and completion (fa19mid1)</p><p>Starvation: a process is prevented from making progress</p><h3 id="policies"><a class="markdownIt-Anchor" href="#policies"></a> Policies</h3><ul><li><p><strong>FIFO / FCFS</strong> (First in first out / First come first serve)</p><ul><li>Run jobs in the order they arrive</li><li>Turnaround time suffers when short jobs must wait for long jobs</li></ul></li><li><p><strong>SJF</strong> (Shortest job first)</p><ul><li>Run remaining job with shortest run time next. 不会打断当前job.</li><li>Optimal for <strong>min turnaround time</strong>.</li><li>缺点: 新来的 short process 会被正在运行的 long process 挡住很长时间 (<strong>starvation</strong>) (<strong>convoy effect</strong> (fa16mid1))</li></ul></li></ul><p>FIFO and SJF are <strong>non-preemptive</strong>: only schedule new job when prev job voluntarily relinquishes CPU.</p><p>(If all jobs have same length, FIFO = SJF) (fa19mid1)</p><p>(将长job移到短job之后能降低turnaround time, 所以SJF能有更短的turnaround). (fa16mid1)</p><p><strong>preemptive</strong>: schedule different jobs by taking CPU away from the running job</p><ul><li><p><strong>STCF</strong> (Shortest Time-to-Completion First)</p><ul><li>Always run job that will complete the quickest. 可能打断当前job.</li><li>如果不断有 short jobs arriving, 则当前的 long job 会 <strong>starve</strong>.</li></ul></li><li><p><strong>RR</strong> (Round Robin)</p><ul><li>Idea: switch more often to reduce response time</li><li>RR <strong>降低 response time</strong>, 但会<strong>增加 turnaround</strong>.</li><li>(如果所有job长度相同, 则RR的turnaround time最差, 因为所有job都在最后才完成) (fa16mid1)</li><li>(Increase the time slice of RR can decrease the overhead imposed by scheduling. 因为 context switch 的次数更少.) (fa19mid1)</li></ul></li></ul><p>The above are not IO aware (jobs hold on CPU while blocked on disk).</p><ul><li><p><strong>I/O aware scheduling</strong></p><ul><li>Treat job A as separate CPU bursts. When A completes IO, another job A is ready.</li></ul></li><li><p><strong>MLFQ</strong> (Multi level feedback queue)</p><ul><li><p>Support both</p><ul><li><strong>interactive</strong> programs that care about <strong>response time</strong></li><li><strong>batch</strong> programs care about <strong>turnaround time</strong></li></ul></li><li><p>multiple levels of round-robin</p></li><li><p>priority levels</p></li><li><p>can preempt them</p></li><li><p>Rules:</p><ul><li><ol><li>If priority A &gt; B, A runs.</li></ol></li><li><ol start="2"><li>If priority A = B, A&amp;B run in RR.</li></ol></li><li><ol start="3"><li>Processes start at top priority.</li></ol></li><li><ol start="4"><li>If job uses whold slice, demote process (longer time slices, lower priorities).</li></ol></li><li><ol start="5"><li>CPU <strong>Burst</strong>: After some time period S, move all jobs to the topmost queue (avoid starvation).</li></ol></li><li><ol start="6"><li><strong>Lottery scheduling</strong>:</li></ol><ul><li>give processes lottery tickets</li><li>whoever wins runs</li><li>higher priority → more tickets</li></ul></li></ul></li><li><p>(One of the goals is to support batch and interactive jobs) (sp22mid1)</p></li></ul></li></ul><p>(<strong>Gantt chart</strong> shows timeline of job scheduling)</p><h1 id="lec-4-virtualization-cpu-to-memory"><a class="markdownIt-Anchor" href="#lec-4-virtualization-cpu-to-memory"></a> Lec 4. Virtualization: CPU to Memory</h1><h2 id="multicore-scheduling"><a class="markdownIt-Anchor" href="#multicore-scheduling"></a> Multicore scheduling</h2><ul><li><p><strong>Single Global Queue</strong></p><p>Advantages:</p><ul><li><p><strong>Low response time</strong> - new tasks can run on any CPU</p></li><li><p><strong>Global priorities</strong> - new task can perrmpt any CPU running lower priority</p></li></ul><p>Drawbacks:</p><ul><li><strong>Expensive communication</strong></li><li>Loss of cache locality when job moves between CPUs</li></ul></li><li><p><strong>Multi-queue Scheduling</strong> (Per-CPU Queue)</p><p>Give each CPU core its own ready quene.</p><p>Tasks assigned to a CPU core when creation.</p><p>Placement policy: <strong>pick the core with shortest queue</strong></p><p>Advantages: No cross-core migration &amp; communication</p><p>Drawbacks: Load imbalance</p></li><li><p><strong>Per-CPU queue with migration</strong></p><p><strong>Periodic rebalancer</strong>: move jobs from cores with many jobs to those with a few jobs</p><p>Run every few seconds (much less frequent as time slice) when load imbalance &gt; 25%</p></li></ul><h2 id="process-creation"><a class="markdownIt-Anchor" href="#process-creation"></a> Process Creation</h2><p>Two ways to create a process</p><h3 id="option-1-new-process-from-scratch-windows"><a class="markdownIt-Anchor" href="#option-1-new-process-from-scratch-windows"></a> Option 1: <strong>New process from scratch</strong> (Windows)</h3><p>Steps</p><ul><li>Load specified code and data into memory; Create empty call stack</li><li>Create and initialize PCB (like context-switch)</li><li>Put process on ready list</li></ul><p>Advantages: no wasted work</p><p>Disadvantages: configuration complicated</p><h3 id="option-2-copy-an-existing-process-and-change-it-appropriately-nix"><a class="markdownIt-Anchor" href="#option-2-copy-an-existing-process-and-change-it-appropriately-nix"></a> Option 2: Copy an existing process and change it appropriately (*nix)</h3><h1 id="lec-5-segmentation-and-paging"><a class="markdownIt-Anchor" href="#lec-5-segmentation-and-paging"></a> Lec 5. Segmentation and Paging</h1><h2 id="static-relocation"><a class="markdownIt-Anchor" href="#static-relocation"></a> Static relocation</h2><h2 id="dynamic-relocation"><a class="markdownIt-Anchor" href="#dynamic-relocation"></a> Dynamic relocation</h2><p>Goal: protect processes from one another</p><p>Requires hardware support: <strong>Memory Management Unit (MMU)</strong></p><p>Dynamic relocation by changing value of base register!</p><p>During context switch, add base and bound registers to PCB.</p><p><strong>Base and bound disadvantages</strong>:</p><ul><li>must be allocated contiguously in physical memory</li><li>must allocate memory that may not be used</li><li>no partial sharing</li></ul><p>(在dynamic relocation中, OS manages the mapping between virtual and physical memory. The OS allocates space in physical memory for each address space.) (fa16mid1)</p><p>(操作系统在物理内存中 allocate space, 编译器在虚拟内存中选择 virtual address) (fa19mid1)</p><p>(<strong>logical address = virtual address</strong>)</p><p>(fa15mid1)</p><h2 id="segmentation"><a class="markdownIt-Anchor" href="#segmentation"></a> Segmentation</h2><p>Divide address space into logical segments, each segment corresponds to logical entity in address space (code, stack, heap)</p><p>Each segment has separate base + bound register.</p><p>MMU contains <strong>Segment Table</strong> (per process).</p><p>Advantages:</p><ul><li>sparse allocation.</li><li>(stack and heap can grow independently)</li></ul><p>Disadvantages:</p><ul><li>externel fragmentation</li></ul><p>(Segmentation 不会增加额外的 memory references. ) (fa19mid1)</p><h1 id="lec-6-paging-tlbs"><a class="markdownIt-Anchor" href="#lec-6-paging-tlbs"></a> Lec 6. Paging - TLBs</h1><h2 id="paging"><a class="markdownIt-Anchor" href="#paging"></a> Paging:</h2><ul><li><p><strong>Goal</strong>: <strong>eliminate</strong> requirement that address space is <strong>contiguous</strong></p></li><li><p>Idea: divide address spaces and physical memory into fixed-sized pages.</p></li><li><p>For each memory reference (steps):</p><ul><li><ol><li><p>Extract <strong>VPN</strong> from <strong>VA</strong> (virt addr)</p></li><li><p>Calculate addr of <strong>PTE</strong> (page table entry)</p><p>PTE address = VPN * PTE size + PTBR (page table base register)</p></li><li><p>Read <strong>PTE</strong> from memory</p></li><li><p>Extract <strong>PFN</strong> (page frame num / physical page number)</p></li><li><p>Build <strong>PA</strong> (phys addr)</p></li><li><p>Read contents of <strong>PA</strong></p></li></ol></li></ul></li><li><p>Every instruction fetch/load/store takes 2 mem references. Slow!</p></li><li><p><strong>Pros:</strong></p><ul><li><strong>No external fragmentation</strong>: any page can be placed in any phys addr</li><li><strong>Fast to allocate and free</strong>: No need to search for suitable free space; doesn’t need adjacent free space</li></ul></li><li><p><strong>Cons</strong>:</p><ul><li><strong>Additional memory reference</strong></li><li><strong>Storage for page tables may be substantial</strong> （PTE needed even if page not allocated)</li></ul></li></ul><h2 id="tlb"><a class="markdownIt-Anchor" href="#tlb"></a> TLB</h2><p><strong>Translation Lookaside Buffer (TLB)</strong></p><p>TLB != PTE (In PTE, we don’t need VPN. In TLB we need.)</p><p>TLB is fully associative.</p><p>Locality</p><img src="/2023/37_cs537/locality.jpeg" srcset="/img/loading.gif" lazyload><h3 id="tlb-replacement-policies"><a class="markdownIt-Anchor" href="#tlb-replacement-policies"></a> TLB replacement policies</h3><ul><li><strong>LRU</strong>: least recently used</li><li><strong>Random</strong>:<ul><li>sometimes random is better</li></ul></li></ul><h3 id="on-context-switches"><a class="markdownIt-Anchor" href="#on-context-switches"></a> On context switches</h3><ul><li>Option 1: <strong>Flush TLB</strong> on context switch</li><li>Option 2: Track which entries are for which process<ul><li>Tag each TLB entry with <strong>Address Space Identifier (ASID)</strong></li></ul></li></ul><p>Hardware or OS handles TLB misses.</p><p>In practice we use hardware. Pagetable structure fixed and agreed between HW and OS. Hardware ‘walks’ pagetable and fills TLB. OS plays no role in TLB miss.</p><p>(<strong>page fault</strong> 的时候: <strong>present bit</strong> 是0)</p><p>(<strong>TLB Miss</strong>的时候是: 找不到entry或者entry的 <strong>valid bit</strong> 是0)</p><p>(fa16mid1)</p><p>(LRU多加一个page 表现会 equal or better)</p><p>(FIFO多加一个page 表现可能会更差: <strong>Belady’s anomaly</strong>)</p><p>(fa19mid1)</p><p>(Page table 里 valid but not present 是说page存在但是被swap到了硬盘上, 需要 trap OS to read disk)</p><h1 id="lec-7-smaller-pagetables"><a class="markdownIt-Anchor" href="#lec-7-smaller-pagetables"></a> Lec 7. Smaller pagetables</h1><h2 id="multi-level-page-tables"><a class="markdownIt-Anchor" href="#multi-level-page-tables"></a> Multi-level page tables</h2><p>Goal: allow page table to be allocated non-contiguously</p><p>Idea: page the page tables (multiple levels)</p><p>Each inner page table fits within a page.</p><h3 id="other-approaches"><a class="markdownIt-Anchor" href="#other-approaches"></a> Other approaches</h3><ul><li>Inverted Page tables</li></ul><h1 id="lec-8-swapping"><a class="markdownIt-Anchor" href="#lec-8-swapping"></a> Lec 8. Swapping</h1><hr><h1 id="lec-10-concurrency"><a class="markdownIt-Anchor" href="#lec-10-concurrency"></a> Lec 10. Concurrency</h1><p>Motivation: 多核</p><ul><li><p>Option 1: many communicating <strong>processes</strong></p></li><li><p>Option 2: <strong>thread</strong> (同一个 process 的多个 thread 共享 address space)</p></li></ul><p>Multi-threaded programs tend to be structured as</p><ul><li><strong>Producer / Consumer</strong></li><li><strong>Pipeline</strong></li><li>Defer work with background thread</li></ul><h2 id="thread-vs-process"><a class="markdownIt-Anchor" href="#thread-vs-process"></a> Thread vs Process</h2><p>Multiple threads within a single process <strong>share</strong>:</p><ul><li>PID</li><li>Address space: code, most data (heap)</li><li>open file descriptors</li><li>current working directory</li><li>User and group ID</li></ul><p>Each thread has <strong>its own</strong></p><ul><li>TID</li><li>set of registers, including ip (instruction pointer) and sp (stack pointer)</li><li>stack</li></ul><h2 id="os-support-approach"><a class="markdownIt-Anchor" href="#os-support-approach"></a> OS support: approach</h2><p><strong>User-level threads: many-to-one thread mapping</strong></p><ul><li>OS is not aware of user-level threads</li><li>advantages: faster, does not require OS support</li><li>disadvantages: cannot leverage multiprocessors; entire process blocks when one thread blocks</li></ul><p><strong>Kernel-level threads: one-to-one thread mapping</strong></p><ul><li>OS provides each user-level thread with a kernel thread</li><li>Each kernel thread scheduled independently.</li><li>advantages: can run parallel on a multiprocessor; when one thread blocks, other threads can be scheduled</li><li>disadvantages: higher overhead for thread operations; OS must scale well with increasing number of threads</li></ul><h1 id="lec-11-locks"><a class="markdownIt-Anchor" href="#lec-11-locks"></a> Lec 11. Locks</h1><h2 id="locks"><a class="markdownIt-Anchor" href="#locks"></a> Locks</h2><ul><li>Allocate and <strong>initialize</strong></li></ul><p>​	<code>Pthread_mutex_t mylock = PTHREAD_MUTEX_INITIALIZER</code></p><ul><li><strong>Acquire</strong><ul><li>Acquire exclusion access to lock</li><li>wait if lock if not avaiable</li><li><strong>spin or block</strong> while waiting</li><li><code>Pthread_mutex_lock(&amp;mylock)</code></li></ul></li><li><strong>Release</strong><ul><li>Release exclusive access to lock</li><li><code>Pthread_mutex_unlock(&amp;mylock)</code></li></ul></li></ul><h3 id="lock-implementation-goals"><a class="markdownIt-Anchor" href="#lock-implementation-goals"></a> <strong>Lock implementation goals</strong></h3><ul><li><strong>Correctness</strong><ul><li><strong>Mutual exclusion</strong>: 同一时刻只能有一个thread在critical section中</li><li><strong>Progress (deadlock-free)</strong>: 不能死锁(大家都无法lock的现象)</li><li><strong>Bounded (starvation-free)</strong>: 不能一直占用着锁</li></ul></li><li><strong>Fairness</strong>: Each thread waits for same amount of time</li><li><strong>Performance</strong>: don’t waste CPU</li></ul><h3 id="atomic-operation-原子操作"><a class="markdownIt-Anchor" href="#atomic-operation-原子操作"></a> <strong>Atomic operation</strong>: 原子操作</h3><p>Approaches</p><ul><li><p>Disable interrupts</p><ul><li>Prevent dispatcher from running another thread</li><li>仅可用于单核; Process可以永久占用CPU; 无法处理其它中断</li></ul></li><li><p>Locks using loads/stores</p><ul><li><p>single shared lock variable, 不行 (memory access not atomic + race condition)</p></li><li><p><strong>XCHG (Atomic exchange or test-and-set)</strong></p><ul><li><pre class="highlight"><code class="c"><span class="hljs-type">int</span> <span class="hljs-title function_">xchg</span><span class="hljs-params">(<span class="hljs-type">int</span> *addr, <span class="hljs-type">int</span> newVal)</span> &#123;
	<span class="hljs-type">int</span> old = *addr;
	*addr = newVal;
	<span class="hljs-keyword">return</span> old;
&#125;
&lt;!--code￼<span class="hljs-number">1</span>--&gt;



</code></pre></li></ul></li></ul></li></ul><p>Fairness issue: scheduler is unaware of locks/unlocks</p><h2 id="ticket-locks"><a class="markdownIt-Anchor" href="#ticket-locks"></a> <strong>Ticket locks</strong></h2><ul><li><p>Idea: reserve each thread’s turn to use a lock. Each thread spins until their turn</p></li><li><p>new atomic primitive, <strong>fetchAndAdd</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">fetchAndAdd</span><span class="hljs-params">(<span class="hljs-type">int</span> *ptr)</span> &#123;<br>	<span class="hljs-type">int</span> old = *ptr;<br>	*ptr = old + <span class="hljs-number">1</span>;<br>	<span class="hljs-keyword">return</span> old;<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p><strong>Acquire</strong>: grab ticket, spin while thread’s ticket != turn</p></li><li><p><strong>Release</strong>: advance to next turn</p></li><li><p>Ticket locks guarantee bounded waiting (bounded by the number of threads). (sp22mid2)</p></li></ul><h2 id="spinlock-performance"><a class="markdownIt-Anchor" href="#spinlock-performance"></a> Spinlock performance</h2><ul><li><strong>Fast</strong> when: 多核; critical section short (lock held a short time)</li><li><strong>Slow</strong> when: 单核; lock held a long time</li><li>advantage: avoid context switch</li><li>disadvantage: spinning is wasteful; fairness issue</li></ul><p><strong>Waste of CPU cycles</strong>:</p><ul><li>Without yield: O(threads * time_slice)</li><li>With yield: O(threads * context_switch)</li></ul><p>Even with yield, spinning is slow with high thread contention</p><p>ticket lock 也属于 spin lock (fa16mid2)</p><h2 id="blocking-when-waiting"><a class="markdownIt-Anchor" href="#blocking-when-waiting"></a> <strong>Blocking when waiting</strong></h2><p>Remove waiting threads from scheduler runnable quene (避免调度正在等候的threads)</p><img src="/2023/37_cs537/blockwhenwaiting.png" srcset="/img/loading.gif" lazyload> <img src="/2023/37_cs537/fixed-blockedwhenwaiting.png" srcset="/img/loading.gif" lazyload><h2 id="spin-waiting-vs-blocking"><a class="markdownIt-Anchor" href="#spin-waiting-vs-blocking"></a> Spin-waiting VS Blocking</h2><p><strong>Uniprocessor</strong> 单核</p><ul><li>waiting process should always relinquish processor</li><li>associate queue of waiters with each lock</li></ul><p><strong>Multiprocessor</strong> 多核</p><ul><li>spin or block <strong>depends on how long</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.61508em;vertical-align:0"></span><span class="mord mathnormal">t</span></span></span></span> <strong>before lock is released</strong><ul><li>lock released quickly (t &lt; C) --&gt; spin-wait</li><li>lock released slowly (t &gt; C) --&gt; block</li><li>C is context-switch cost</li></ul></li></ul><h3 id="two-phase-waiting"><a class="markdownIt-Anchor" href="#two-phase-waiting"></a> Two-phase waiting</h3><p>Algorithm: <strong>spin-wait for C then block</strong></p><p>Two cases:</p><ul><li>if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.61508em;vertical-align:0"></span><span class="mord mathnormal">t</span></span></span></span> actually &lt; C, spin-wait for <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.61508em;vertical-align:0"></span><span class="mord mathnormal">t</span></span></span></span>, we are same as optimal</li><li>if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.61508em;vertical-align:0"></span><span class="mord mathnormal">t</span></span></span></span> actually &gt; C, we pay spin C then block (twice as bad as optimal)</li><li>worst-case performance bounded</li></ul><p><strong>2-competitive algorithm</strong></p><h1 id="lec-12-condition-variables"><a class="markdownIt-Anchor" href="#lec-12-condition-variables"></a> Lec 12. Condition Variables</h1><h3 id="concurrency-objectives"><a class="markdownIt-Anchor" href="#concurrency-objectives"></a> <strong>Concurrency objectives</strong></h3><ul><li><strong>mutual exclusion</strong> (A和B不能同时运行)<ul><li>Solved with <strong>locks</strong></li></ul></li><li><strong>Ordering</strong> (B一定要在A之后运行)<ul><li>Solved with <strong>condition variables</strong> and <strong>semaphores</strong></li></ul></li></ul><h3 id="condition-variables"><a class="markdownIt-Anchor" href="#condition-variables"></a> Condition variables</h3><p>Condition variable: <strong>queue of waiting threads</strong></p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.05017em">B</span></span></span></span> waits for a signal on CV before running</p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal">A</span></span></span></span> sends signal to CV when time for B to run</p><ul><li><strong>wait(cv, lock)</strong><ul><li>requires the lock is held when wait() called</li><li>sleep + release the lock (atomically)</li><li>when awoken, re-acquire the lock before returning</li></ul></li><li><strong>signal(cv)</strong><ul><li>wakes a single waiting thread (if any)</li><li>if no waiting thread, do nothing</li></ul></li></ul><p>CV needs lock to prevent race conditions around shared state</p><h3 id="rule-of-thumb-1-经验法则"><a class="markdownIt-Anchor" href="#rule-of-thumb-1-经验法则"></a> Rule of thumb 1 (经验法则)</h3><p><strong>Keep state</strong> in addition to CV(s).</p><p>CV’s are used to signal threads when state changes. If state is already as needed, thread doesn’t wait for a signal.</p><img src="/2023/37_cs537/cv-thread-join.png" srcset="/img/loading.gif" lazyload><h3 id="example-unix-pipes"><a class="markdownIt-Anchor" href="#example-unix-pipes"></a> Example: unix pipes</h3><p>finite-sized buffer</p><p>Writers add data to the buffer (need to wait if buffer is full)</p><p>Readers remove data from the buffer (need to wait if buffer is empty)</p><h3 id="rule-of-thumb-2"><a class="markdownIt-Anchor" href="#rule-of-thumb-2"></a> Rule of thumb 2</h3><p>Always do wait/signal with lock held.</p><p>CV needs lock to prevent race conditions around shared state.</p><h3 id="rule-of-thumb-3"><a class="markdownIt-Anchor" href="#rule-of-thumb-3"></a> Rule of thumb 3</h3><p>Whenever a <strong>lock</strong> is <strong>acquired</strong>, <strong>recheck assumptions</strong> about state!</p><p>Another thread could grab lock in between signal and wakeup from wait.</p><h3 id="rule-of-thumb-4"><a class="markdownIt-Anchor" href="#rule-of-thumb-4"></a> Rule of thumb 4</h3><p>Have a separate CV for each condition</p><p>(Ensures waking up the right thread)</p><h1 id="lec-13-semaphores"><a class="markdownIt-Anchor" href="#lec-13-semaphores"></a> Lec 13. Semaphores</h1><p>CV have no <strong>state</strong> (other than the waiting queue)</p><p>Semaphores have <strong>state</strong>: track <strong>integer value</strong></p><h3 id="semaphore-operations"><a class="markdownIt-Anchor" href="#semaphore-operations"></a> Semaphore operations</h3><ul><li>allocate and initialize<ul><li><code>sem_init(...) &#123; s-&gt;value = initval; &#125;</code></li><li>User cannot R/W value directly</li></ul></li><li><strong>Wait or Test</strong>: <code>sem_wait(sem_t *)</code><ul><li>value–; waits if value is negative (&lt;0)</li></ul></li><li><strong>Signal or Post</strong>: <code>sem_post(sem_t *)</code><ul><li>value++; wake a single waiter if exists</li></ul></li></ul><p><strong>Value of semaphore</strong>:</p><ul><li>when &gt;= 0: number of available slots</li><li>when &lt;0: number of waiting threads</li></ul><h1 id="lec-14-deadlock"><a class="markdownIt-Anchor" href="#lec-14-deadlock"></a> Lec 14. Deadlock</h1><p>Deadlock: no progress can be made because &gt;=2 threads are waiting for the other to take some action and thus neither ever does.</p><h3 id="deadlock-theory"><a class="markdownIt-Anchor" href="#deadlock-theory"></a> Deadlock theory</h3><p>Deadlocks can only happen with these 4 conditions</p><ul><li><p><strong>mutual exclusion</strong></p><ul><li><p>problem: threads claim exclusive control of resources that they acquire</p></li><li><p>solution: try to replace locks with atomic primitive 用原子操作代替锁</p></li></ul></li><li><p><strong>hold-and-wait</strong></p><ul><li><p>problem: threads hold resources allocated to them while waiting for additional resources</p></li><li><p>solution: acquire all locks atomically once (by using a <strong>meta lock</strong>)</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c">lock(&amp;meta);<br>lock(&amp;L1);<br>lock(&amp;L2);<br>...<br>unlock(&amp;meta);<br><span class="hljs-comment">// critical section code here</span><br>unlock(...);<br></code></pre></td></tr></table></figure></li></ul></li><li><p><strong>no preemption</strong></p><ul><li><p>problem: resources (e.g. locks) cannot be forcibly removed from threads</p></li><li><p>strategy: if thread cannot get what it wants, release what it holds</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c">top:<br>	lock(A);<br>	<span class="hljs-keyword">if</span> (trylock(B) fails) &#123;<br>		unlock(A);<br>		<span class="hljs-keyword">goto</span> top;<br>	&#125;<br></code></pre></td></tr></table></figure></li><li><p>disadvantages: <strong>livelock</strong></p></li></ul></li><li><p><strong>circular wait</strong></p><ul><li>problem: circular chain of threads such that each thread holds a resource (e.g. lock) being requested by next thread in the chain.</li><li>strategy:<ul><li>decide which locks should be acquired before others</li><li>if A before B, never acquire A if B is already held</li><li>document this</li></ul></li></ul></li></ul><hr><h1 id="lec-15-io"><a class="markdownIt-Anchor" href="#lec-15-io"></a> Lec 15. IO</h1><p><strong>Canonical device</strong></p><h3 id="interrupts-vs-pooling"><a class="markdownIt-Anchor" href="#interrupts-vs-pooling"></a> Interrupts vs Pooling</h3><p>Fast device: better to spin</p><p>Floods of interrupts arrive can lead to <strong>livelock</strong> (CPU always handling interrupts)</p><p>Pooling has lower latency.</p><h1 id="lec-17-raid-files"><a class="markdownIt-Anchor" href="#lec-17-raid-files"></a> Lec 17. RAID &amp; Files</h1><p>Sometimes we want many disks: <strong>capacity</strong>. <strong>reliability</strong>, <strong>performance</strong></p><h2 id="raid-0-striping-切片"><a class="markdownIt-Anchor" href="#raid-0-striping-切片"></a> RAID-0: striping 切片</h2><p>Optimize for <strong>capacity</strong>.</p><p>No redundancy. Disk数量越多, 可靠性越低.</p><ul><li>capacity: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">N\times C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span></span></span></span></li><li>no disks can we safely lose</li><li>latency: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.02778em">D</span></span></span></span></li><li>sequential throughput: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">N\times S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.05764em">S</span></span></span></span></li><li>random throughput: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mi>R</mi></mrow><annotation encoding="application/x-tex">N\times R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.00773em">R</span></span></span></span></li></ul><h2 id="raid-1-mirroring-镜像"><a class="markdownIt-Anchor" href="#raid-1-mirroring-镜像"></a> RAID-1: mirroring 镜像</h2><ul><li>capacity: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo>∗</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">N/2 * C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mord">/</span><span class="mord">2</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span></span></span></span></li><li>how many disks can fail: at least 1, at most <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mi mathvariant="normal">/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">N/2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mord">/</span><span class="mord">2</span></span></span></span></li><li>latency: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.02778em">D</span></span></span></span> (write to both disks)</li></ul><h2 id="raid-4-parity盘"><a class="markdownIt-Anchor" href="#raid-4-parity盘"></a> RAID-4: parity盘</h2><ul><li>capacity: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>∗</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">(N-1)*C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span></span></span></span></li><li>how many disks can fail: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span></li><li>latency: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.02778em">D</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>D</mi></mrow><annotation encoding="application/x-tex">2D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:.02778em">D</span></span></span></span> for random (read and write parity disk)</li></ul><h2 id="raid-5-轮流承担parity盘"><a class="markdownIt-Anchor" href="#raid-5-轮流承担parity盘"></a> RAID-5: 轮流承担parity盘</h2><ul><li>capacity: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>∗</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">(N-1)*C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span></span></span></span></li><li>how many disks can fail: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span></li><li>latency: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.02778em">D</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>D</mi></mrow><annotation encoding="application/x-tex">2D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:.02778em">D</span></span></span></span> (read and write parity disk)</li></ul><img src="/2023/37_cs537/raid-comparison.png" srcset="/img/loading.gif" lazyload><h1 id="lec-18-files"><a class="markdownIt-Anchor" href="#lec-18-files"></a> Lec 18. Files</h1><h2 id="file-descriptor-fd"><a class="markdownIt-Anchor" href="#file-descriptor-fd"></a> File descriptor (FD)</h2><ul><li><code>int</code>类型, points to inode</li><li>FD中存了offset</li><li>每个process有自己的fd table</li><li>用dup创建的新file descriptor会复制同样的offset</li></ul><h2 id="fsyncint-fd"><a class="markdownIt-Anchor" href="#fsyncint-fd"></a> fsync(int fd)</h2><ul><li><strong>write buffering</strong> (file system keeps newly written data in memory for a while)</li><li>fsync forces buffers to flush to disk from memory</li></ul><h2 id="deleting-files"><a class="markdownIt-Anchor" href="#deleting-files"></a> Deleting files</h2><ul><li>There is no syscall for deleting files</li><li>Inode and associated file is <strong>garbage collected</strong> when no references (no directory pointing to the inode)</li><li>Paths are deleted when <code>unlink()</code> is called</li><li>FDs are deleted when <code>close()</code> or process quits.</li><li>What will happen if file is opened (has fd) when unlink() is called? : File automatically deleted after fd closes</li></ul><h2 id="rename"><a class="markdownIt-Anchor" href="#rename"></a> Rename</h2><ul><li><code>rename(char *old, char *new)</code></li><li>deletes an old link to a file, creates a new link to a file</li><li>just changes filename, does not move data</li></ul><h2 id="links"><a class="markdownIt-Anchor" href="#links"></a> Links</h2><h3 id="hardlink"><a class="markdownIt-Anchor" href="#hardlink"></a> Hardlink</h3><ul><li><p>Hardlink: both path names use the same inode number (two links for the same file)</p></li><li><p>File does not disappear until all hard links removed</p></li><li><p><strong>cannot hardlink directories</strong></p></li><li><p>command: <code>ln &lt;new filename&gt; &lt;current filename&gt;</code></p></li></ul><h3 id="softlink"><a class="markdownIt-Anchor" href="#softlink"></a> Softlink</h3><ul><li>soft or symbolic links: point to second path name</li><li>can softlink to directories</li><li>command: <code>ln -s &lt;oldfile&gt; &lt;softlink&gt;</code></li><li>can point to anything, but the file you are pointing to may not exist</li><li>confusing behavior: “file does not exist”</li><li>confusing behavior: “cd linked_dir; cd …” in different parent</li></ul><h2 id="fs-structs"><a class="markdownIt-Anchor" href="#fs-structs"></a> FS structs</h2><img src="/2023/37_cs537/fs-structs.png" srcset="/img/loading.gif" lazyload><h2 id="allocation-strategies"><a class="markdownIt-Anchor" href="#allocation-strategies"></a> Allocation strategies</h2><h3 id="1-contiguous-allocation"><a class="markdownIt-Anchor" href="#1-contiguous-allocation"></a> 1. contiguous allocation</h3><p>(similar to base-and-bound) Allocate each file to <strong>contiguous</strong> sectors <strong>on disk</strong>.</p><p><strong>Fastest</strong> file system, but</p><ul><li>horrible <strong>external fragmentation</strong>, and</li><li>may not be able to write new data without moving</li></ul><img src="/2023/37_cs537/fs-contiguous-allocation.png" srcset="/img/loading.gif" lazyload><h3 id="2-small-fixed-number-of-extents"><a class="markdownIt-Anchor" href="#2-small-fixed-number-of-extents"></a> 2. small (fixed) number of extents</h3><p>Allocate multiple contiguous regions (extents) per file.</p><p>Still has <strong>external fragmentation</strong>.</p><img src="/2023/37_cs537/fs-small-fixed-num-extents.png" srcset="/img/loading.gif" lazyload><h3 id="3-linked-allocation"><a class="markdownIt-Anchor" href="#3-linked-allocation"></a> 3. linked allocation</h3><p>Allocate linked-list of fixed-sized blocks (multiple sectors)</p><ul><li><strong>No external fragmentation</strong></li><li><strong>Very poor random access</strong></li></ul><img src="/2023/37_cs537/fs-linked-allocation.png" srcset="/img/loading.gif" lazyload><h3 id="4-indexed-allocation"><a class="markdownIt-Anchor" href="#4-indexed-allocation"></a> 4. indexed allocation</h3><p>put all pointers together into index block;</p><p>allocate space for pointers when creating files</p><ul><li>No external fragmentation</li><li>good random access performance</li></ul><img src="/2023/37_cs537/fs-indexed-allocation.png" srcset="/img/loading.gif" lazyload><h3 id="5-multi-level-indexing"><a class="markdownIt-Anchor" href="#5-multi-level-indexing"></a> 5. multi-level indexing</h3><img src="/2023/37_cs537/fs-multilevel-indexing.png" srcset="/img/loading.gif" lazyload><h1 id="lec-21-ffs-fast-file-system"><a class="markdownIt-Anchor" href="#lec-21-ffs-fast-file-system"></a> Lec 21. FFS (Fast file system)</h1><h2 id="disk-aware-file-system"><a class="markdownIt-Anchor" href="#disk-aware-file-system"></a> Disk-aware file system</h2><p><strong>Groups</strong></p><ul><li><img src="/2023/37_cs537/ffs-group.png" srcset="/img/loading.gif" lazyload></li><li><p>key idea: keep inode close to data</p></li></ul><img src="/2023/37_cs537/ffs-policy.png" srcset="/img/loading.gif" lazyload><ul><li>FFS policy summary</li></ul><img src="/2023/37_cs537/ffs-policy-summary.png" srcset="/img/loading.gif" lazyload><h2 id="fs-consistency"><a class="markdownIt-Anchor" href="#fs-consistency"></a> FS consistency</h2><p>Problem: interrupt (power loss …) may leave data in inconsistent state</p><img src="/2023/37_cs537/fs-consistency-example.png" srcset="/img/loading.gif" lazyload><p>Solution</p><ul><li><strong>FSCK</strong><ul><li>After crash, <strong>scan whole disk for contradictions</strong> and “fix” if needed</li><li>keep FS off-line until FSCK completes</li><li>Problem:<ul><li>Not always obvious how to fix file system image</li><li><strong>Don’t know correct state</strong>, just consistent one (seemingly correct but may not be correct)</li><li>Slow</li></ul></li></ul></li><li><strong>Journaling</strong>- get correct state<ul><li>TODO</li></ul></li></ul><h1 id="lec-23-ssd"><a class="markdownIt-Anchor" href="#lec-23-ssd"></a> Lec 23. SSD</h1><h1 id="lec-24-distributed-systems"><a class="markdownIt-Anchor" href="#lec-24-distributed-systems"></a> Lec 24. Distributed Systems</h1><p>Definition: more than 1 machine working together to solve a problem.</p><p>Challenges: <strong>partial</strong> failure; communication failure</p><h2 id="udp-user-datagram-protocol"><a class="markdownIt-Anchor" href="#udp-user-datagram-protocol"></a> UDP (User Datagram Protocol)</h2><p>Minimal reliability</p><p>Message might be <strong>lost</strong>, <strong>reordered</strong>, <strong>duplicated</strong>.</p><p>The <strong>only protection</strong> is that data <strong>will not be corrupted</strong>.</p><p>Advantages: lightweight</p><h2 id="tcp-transmission-control-protocol"><a class="markdownIt-Anchor" href="#tcp-transmission-control-protocol"></a> TCP (Transmission Control Protocol)</h2><p>Reliable logical connections over unreliable physical connections.</p><h3 id="technique-1-ack"><a class="markdownIt-Anchor" href="#technique-1-ack"></a> Technique 1: ACK</h3><p>Before sending data, establish connection</p><img src="/2023/37_cs537/TCP-ack.png" srcset="/img/loading.gif" lazyload><h3 id="technique-2-timeout"><a class="markdownIt-Anchor" href="#technique-2-timeout"></a> Technique 2: Timeout</h3><p>For each missing ack, wait longer between retries.</p><h3 id="technique-3-receiver-remembers-messages"><a class="markdownIt-Anchor" href="#technique-3-receiver-remembers-messages"></a> Technique 3: receiver remembers messages</h3><p>Solution: <strong>sequence numbers</strong></p><ul><li>sender gives each message an <strong>increasing</strong> <strong>unique</strong> <strong>sequence number</strong></li><li>receiver suppress message if the message’s seq number &lt; N or it is already buffered</li><li>buffers messages to ensure messages are handled in order</li></ul><h2 id="rpc-remote-procedure-call"><a class="markdownIt-Anchor" href="#rpc-remote-procedure-call"></a> RPC (Remote Procedure Call)</h2><p>Approach: create wrappers so calling a function on another machine feels just like calling a local function.</p><img src="/2023/37_cs537/rpc.png" srcset="/img/loading.gif" lazyload><p>Wrapper generation:</p><ul><li>wrappers must do conversions: uniform endianness (little endian/big endian), pointers, …</li><li>conversion is called <strong>marshaling</strong>/unmarshaling, or <strong>serializing</strong>/deserializing</li></ul><h2 id="distributed-file-systems"><a class="markdownIt-Anchor" href="#distributed-file-systems"></a> Distributed file systems</h2><p>NFS (network file system)</p><img src="/2023/37_cs537/nfs.png" srcset="/img/loading.gif" lazyload><p><strong>Strategy 1</strong>:</p><ul><li><p>open() on client calls open() on server, open() on server returns fd back to client;</p><p>read(fd) on client calls read(fd) on server, …</p></li><li><p>Problem: server crashs during several client read(fd) operations</p></li></ul><p><strong>Strategy 2</strong>: put all info in requests</p><ul><li><p>Use <strong>stateless</strong> protocol: server maintains no state about clients</p></li><li><p>Need api change. One possibility:</p><ul><li><p><code>pread(char *path, buf, size, offset)</code></p><p><code>pwrite(char *path, buf, size, offset)</code></p></li></ul></li><li><p>Advantage: server can crash and reboot transparently to clients.</p></li><li><p>Disadvantage: too many path lookups</p></li></ul><p><strong>Strategy 3</strong>: inode requests</p><ul><li><p><code>inode = open(char *path)</code></p><p><code>pread(inode, buf, size, offset)</code></p><p><code>pwrite(inode, buf, size, offset)</code></p></li><li><p>Good</p></li><li><p>Disadvantage: if file deleted, inode could be reused</p></li></ul><p><strong>Strategy 4</strong>: file handles</p><ul><li><p><code>fh = open(char *path)</code></p></li><li><p>File handle = &lt;volume ID, inode number, <strong>generation number</strong>&gt; (extended inode number)</p></li><li><p>Opaque to client (client cannot see the internals)</p></li><li><p><strong>Idempotent operations</strong>: if f() is idempotent, then f() f() f() has the same effect as f()</p><p>e.g. pwrite(fh, buf, size, offset) is idempotent; append(fh, buf, size) is not idempotent</p></li></ul><p><strong>Strategy 5</strong>: client logic</p><p>write buffering</p></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/Lecture-Notes/" class="category-chain-item">Lecture Notes</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/Lecture-Notes/" class="print-no-link">#Lecture Notes</a></div></div><div class="license-box my-3"><div class="license-title"><div>[Lecture Notes] UW-Madison CS537 Operating Systems</div><div>https://www.billhu.us/2023/37_cs537/</div></div><div class="license-meta"><div class="license-meta-item"><div>Author</div><div>Bill Hu</div></div><div class="license-meta-item license-meta-date"><div>Posted on</div><div>May 10, 2023</div></div><div class="license-meta-item"><div>Licensed under</div><div><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - Attribution"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/2023/40_cs252/" title="[Lecture Notes] ShanghaiTech CS252 Cryptography"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">[Lecture Notes] ShanghaiTech CS252 Cryptography</span> <span class="visible-mobile">Previous</span></a></article><article class="post-next col-6"><a href="/2023/38_cs564/" title="[Lecture Notes] UW-Madison CS564 Database Mgt Systems"><span class="hidden-mobile">[Lecture Notes] UW-Madison CS564 Database Mgt Systems</span> <span class="visible-mobile">Next</span> <i class="iconfont icon-arrowright"></i></a></article></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>Table of Contents</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">Search</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">Keyword</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <span>With </span><a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> <i class="iconfont icon-love"></i> <a href="/about" target="_blank" rel="nofollow noopener"><span>Bill Hu</span></a><div style="font-size:.85rem"><span id="timeDate">Loading days...</span> <span id="times">Loading time...</span><script src="/js/duration.min.js"></script></div></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t){var e=Fluid.plugins.typing,t=t.getElementById("subtitle");t&&e&&e(t.getAttribute("data-typed-text"))}((window,document))</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",function(){var t,o=jQuery("#toc");0!==o.length&&window.tocbot&&(t=jQuery("#board-ctn").offset().top,window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-t},CONFIG.toc)),0<o.find(".toc-list-item").length&&o.css("visibility","visible"),Fluid.events.registerRefreshCallback(function(){var t;"tocbot"in window&&(tocbot.refresh(),0!==(t=jQuery("#toc")).length)&&tocbot&&0<t.find(".toc-list-item").length&&t.css("visibility","visible")}))})</script><script src="https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n,o=[];for(n of(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","))o.push(".markdown-body > "+n.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback(function(){if("anchors"in window){anchors.removeAll();var n,o=[];for(n of(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","))o.push(".markdown-body > "+n.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}})})</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",function(){Fluid.plugins.fancyBox()})</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">Blog works best with JavaScript enabled</div></noscript></body></html>