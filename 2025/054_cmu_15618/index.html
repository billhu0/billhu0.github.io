<!DOCTYPE html><html lang="en" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png"><link rel="icon" href="/img/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="Bill Hu"><meta name="keywords" content=""><meta name="description" content="CMU 15-618 Notes"><meta property="og:type" content="article"><meta property="og:title" content="[Lecture Notes] CMU 15-618 Parallel Computer Architecture &amp; Programming"><meta property="og:url" content="https://www.billhu.us/2025/054_cmu_15618/index.html"><meta property="og:site_name" content="Bill Hu&#39;s Blog"><meta property="og:description" content="CMU 15-618 Notes"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://www.billhu.us/2025/054_cmu_15618/interleave-thread.png"><meta property="article:published_time" content="2025-01-07T19:17:06.000Z"><meta property="article:modified_time" content="2025-01-16T21:00:10.869Z"><meta property="article:author" content="Bill Hu"><meta property="article:tag" content="C"><meta property="article:tag" content="Lecture Notes"><meta property="article:tag" content="CUDA"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://www.billhu.us/2025/054_cmu_15618/interleave-thread.png"><title>[Lecture Notes] CMU 15-618 Parallel Computer Architecture &amp; Programming - Bill Hu&#39;s Blog</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/KaTeX/0.15.6/katex.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="/css/myfont.css"><link rel="stylesheet" href="/css/jetbrains-mono.css"><script id="fluid-configs">var dntVal,Fluid=window.Fluid||{},CONFIG=(Fluid.ctx=Object.assign({},Fluid.ctx),{hostname:"www.billhu.us",root:"/",version:"1.9.7",typing:{enable:!0,typeSpeed:25,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:3},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1},gtag:null},search_path:"/local-search.xml",include_content_in_search:!0});CONFIG.web_analytics.follow_dnt&&(dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on")))</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><script>!function(t,e,n,c,a,r){t[n]=t[n]||function(){(t[n].q=t[n].q||[]).push(arguments)},(a=e.createElement(c)).async=1,a.src="https://www.clarity.ms/tag/fjnxcr4gva",(r=e.getElementsByTagName(c)[0]).parentNode.insertBefore(a,r)}(window,document,"clarity","script")</script><meta name="google-site-verification" content="IqNfw3GiMxuhw7kYoEdhMJoh3j99KHuGI9bw00hPn2c"><link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Kaushan+Script" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700" rel="stylesheet"><meta name="generator" content="Hexo 7.1.1"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Bill Hu&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/" target="_self"><i class="iconfont icon-home-fill"></i> <span>Home</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/" target="_self"><i class="iconfont icon-archive-fill"></i> <span>Archives</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/" target="_self"><i class="iconfont icon-category-fill"></i> <span>Categories</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/" target="_self"><i class="iconfont icon-tags-fill"></i> <span>Tags</span></a></li><li class="nav-item"><a class="nav-link" href="/about/" target="_self"><i class="iconfont icon-user-fill"></i> <span>About</span></a></li><li class="nav-item"><a class="nav-link" href="https://www.billhu.xyz" target="_self"><i class="iconfont icon-code"></i> <span>Portfolio</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/default.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="[Lecture Notes] CMU 15-618 Parallel Computer Architecture &amp; Programming"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2025-01-07 19:17" pubdate>January 7, 2025 pm</time></span></div><div class="mt-1"></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 id="seo-header">[Lecture Notes] CMU 15-618 Parallel Computer Architecture &amp; Programming</h1><div class="markdown-body"><h1 id="lec-2-a-modern-multi-core-processor"><a class="markdownIt-Anchor" href="#lec-2-a-modern-multi-core-processor"></a> Lec 2. A modern multi-core processor</h1><p>4 key concepts: 两个与parallel execution有关, 两个与challenges of accessing memory 有关</p><h2 id="parallel-execution"><a class="markdownIt-Anchor" href="#parallel-execution"></a> Parallel execution</h2><ul><li><strong>Superscalar processor</strong>: Instruction level parallelism (ILP)<ul><li>ILP读未来的指令（每个周期读两条指令），有两个fetch/decode单元和两个exec单元，能够同时执行两条指令</li></ul></li><li><strong>Multi-core</strong>: 多个processing cores<ul><li>多核之前，处理器提升重点在更大缓存，更多分支预测predictor等；同时更多晶体管（才能放得下更多缓存和更多predictor和乱序执行逻辑）促生更小的晶体管，促进更高的计算机主频</li><li>2004年多核出现之后，人们在一个chip上放多个processor，用更多晶体管放更多核心。</li></ul></li><li><strong>SIMD processing</strong> (aka <strong>Vector processing</strong>): 多个ALU(同一个core内)<ul><li>仍然只需要一个fetch/decode单元，多个ALU。</li><li>conditional execution: 如果想simd的程序块有if else，要通过mask处理</li><li>手写avx代码（cpu指令）是<strong>explicit SIMD</strong>; 而GPU是<strong>implicit SIMD</strong>，因为compiler生成的并不是并行指令（是普通的scalar instructions），只有GPU硬件运行才是SIMD的</li></ul></li></ul><h2 id="accessing-memory"><a class="markdownIt-Anchor" href="#accessing-memory"></a> Accessing memory</h2><ul><li><p><strong>cache</strong>: <strong>reduce latency</strong></p></li><li><p><strong>prefetching</strong> reduces stalls: <strong>hides latency</strong></p></li><li><p><strong>Multi-threading</strong>, <strong>interleave</strong> processing of multiple threads</p><ul><li>跟prefetching一样，也是hide latency，不能reduce latency</li><li>指的是：开多个线程，在一个线程卡住的时候执行别的线程</li><li>在下图中，创建thread1的时候不仅仅创建thread1，还会告诉电脑创建了thread 2 3 4，硬件检测线程是否发生了stall（被等待内存操作卡住），如果发生了stall会很快切换到别的线程，想juggling一样。硬件决定如何juggle这些线程。</li><li>这样memory latency仍然存在，但是被hide了。memory latency在后台发生，前台CPU一直在执行有用的工作。</li><li>这种操作会导致单个线程的执行时间变长（因为thread1从runnable到重新开始执行有一段空挡（这段空隙在执行thread 2 3 4）。</li><li>需要更多硬件资源，存储线程的register等状态信息，这样切换线程才会快。且需要较大的memory bandwidth。</li></ul></li></ul><img src="/2025/054_cmu_15618/interleave-thread.png" srcset="/img/loading.gif" lazyload><p>GPU设计成处理大量数据（远大于核内缓存的数据量）。</p><p>与CPU内存相比，GPU显存带宽更高，但延迟更高。</p><h1 id="一些基础知识"><a class="markdownIt-Anchor" href="#一些基础知识"></a> 一些基础知识</h1><h2 id="ispc"><a class="markdownIt-Anchor" href="#ispc"></a> ISPC</h2><p>ISPC代码调用时会生成多个program instances, 可以利用 <code>programCount</code> 和 <code>programIndex</code> 来获取instance总数和当前instance编号。</p><p><code>uniform</code> 表示在一个SIMD程序块中，变量对所有SIMD通道都是相同的值。仅仅是一种优化，不影响正确性(因为uniform变量只需要加载一次或执行一次，编译器可以做出优化，不加uniform可能造成不必要的重复计算)。</p><p>非uniform (<code>varying</code>) 表示变量在不同SIMD通道可能有不同的值。</p><p>所以说 <code>programCount</code> 是 uniform, <code>programIndex</code> 是 varying.</p><hr><p>ISPC可以通过tasks来实现多核加速，利用多线程。</p><p>Contrary to threads, tasks do not have execution context and they are only pieces of work. ISPC编译器接受tasks并自行决定启动多少个threads。</p><p>通常我们应该启动比cpu逻辑线程数更多的tasks数量，但也不要太多，否则会有scheduling的overhead。</p><p>task自带 <code>taskIndex</code>。</p><h2 id="cuda"><a class="markdownIt-Anchor" href="#cuda"></a> CUDA</h2><p>host是CPU, device是GPU</p><p><code>__device__</code>: 在device上执行，只能在device中调用</p><p><code>__global__</code>: 在device上执行，只能在host中调用</p><p><code>__host__</code>: 在host上执行且只能在host上调用</p><p><code>cudaMemcpy(dst, src, size, cudaMemcpyDeviceToHost)</code></p><hr><p>threads grouped into blocks</p><p>需要指明blocks的数量，和每个block中threads的数量。</p><p>假设n是总的threads数量, t是每个block中threads的数量。</p><p><code>KernelFunction&lt;&lt;&lt;ceil(n/t), t&gt;&gt;&gt;(args)</code></p><p>每一个thread都会运行同样的kernel，每一个thread由blockID和这个block中的threadID来标识。</p><hr><p>Example:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs c">__global__ <span class="hljs-type">void</span> <span class="hljs-title function_">vecAddKernel</span><span class="hljs-params">(<span class="hljs-type">float</span>* A, <span class="hljs-type">float</span>* B, <span class="hljs-type">float</span>* C, <span class="hljs-type">int</span> n)</span> &#123;<br>    <span class="hljs-type">int</span> i = threadId.x + blockDim.x * blockId.x;<br>    <span class="hljs-keyword">if</span> (i&lt;n) C[i] = A[i] + B[i];<br>&#125;<br><span class="hljs-type">void</span> <span class="hljs-title function_">vecAdd</span><span class="hljs-params">(<span class="hljs-type">float</span>* A, <span class="hljs-type">float</span>* B, <span class="hljs-type">float</span>* C, <span class="hljs-type">int</span> n)</span> &#123;<br>    <span class="hljs-type">int</span> size = n * <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">float</span>);<br>    <span class="hljs-type">float</span> *d_A, *d_B, *d_C;<br>  <br>    cudaMalloc((<span class="hljs-type">void</span> **) &amp;d_A, size);<br>    cudaMemcpy(d_A, A, size, cudaMemcpyHostToDevice);<br>    cudaMalloc((<span class="hljs-type">void</span> **) &amp;d_B, size);<br>    cudaMemcpy(d_B, B, size, cudaMemcpyHostToDevice);<br>    cudaMalloc((<span class="hljs-type">void</span> **) &amp;d_C, size);<br>  <br>    vecAddKernel&lt;&lt;&lt;<span class="hljs-built_in">ceil</span>(n/<span class="hljs-number">256</span>), <span class="hljs-number">256</span>&gt;&gt;&gt;(d_A, d_B, d_C, n);<br>    <br>  	cudaMemcpy(C, d_C, size, cudaMemcpyDeviceToHost);<br>    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);<br>&#125;<br></code></pre></td></tr></table></figure><p>注: 为什么<code>cudaMalloc</code>第一个参数是二级指针，而不直接使用返回值来赋值给指针？</p><p>因为 <code>cudaMalloc</code> 的返回值已经用来返回 <code>cudaError_t</code>。</p><hr><p>grid和blocks可以是1D, 2D, 3D的。上面这个例子是1D，所以是&quot;<code>.x</code>&quot;</p><p>2D的例子：假设要把一个WIDTH x WIDTH的矩阵P分成几块。</p><p>WIDTH=8, TILE_WIDTH为2的话，就是把8x8的矩阵分成16个小块(grid)，每一个小块大小是2x2(4个thread)。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c">dim3 <span class="hljs-title function_">dimGrid</span><span class="hljs-params">(WIDTH / TILE_WIDTH, WIDTH / TILE_WIDTH, <span class="hljs-number">1</span>)</span>;<br>dim3 <span class="hljs-title function_">dimBlock</span><span class="hljs-params">(TILE_WIDTH, TILE_WIDTH, <span class="hljs-number">1</span>)</span>;<br>MatrixMulKernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(args);<br></code></pre></td></tr></table></figure><p>每一个thread可以用以下方式来标识</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">row    = blockId.y * blockDim.y + threadId.y;<br>column = blockId.x * blockDim.x + threadId.x;<br></code></pre></td></tr></table></figure><hr><p>为什么用两层threads？因为组成多个grid的thread blocks比一个很大的单个thread block更好管理。</p><p>GPU有很多很多核心，核心group成SM(streaming multiprocessors)，每一组SM有自己的内存和调度。</p><p>GPU不同时启动所有100万个threads，而是把大约1000个thread装进一个block里，并分发给SM。</p><p>assign给SM的thread block会使用SM的资源（寄存器和共享内存）。这些资源已经pre-allocated，且由于寄存器数量很多，在切换threads时不需要register flush。</p><hr><p>不同的block可以用任何顺序运行，因此不能assume block2在block1之后运行。如果真的要这么做，需要放在不同的kernel里（启动kernel比较耗资源）</p><p>同一个block中的thread可以使用 <code>__syncthreads()</code> 来做barrier synchronization。</p><p>但是通常不建议使用 <code>__syncthreads()</code></p><hr><p>如何选择合适的block size？</p><ul><li>Consideration 1: hardware constraints<ul><li>例如：每一个SM分配小于1536个thread，小于8个block；每一个block小于512个thread</li></ul></li><li>Consideration 2: complexity of each thread</li><li>Consideration 3: thread work imbalance.</li></ul><hr><p>GPU memory</p><p>Global memory很慢，所以同时运行大量线程，线程因为内存IO卡住的时候切换其它线程，这是massive multi-threading (MMT).</p><p>这样总的throughput很高，即使每个thread的延迟也很高。</p><p>每个SM有自己的scheduler，每个SM存储了所有thread的context(PC, reg等)，所以SM内能做到零开销线程切换。同时，SM scheduler有一个scoreboard追踪哪些thread是blocked/unblocked，所以SM有大约30个核但可以运行大约1000个线程。</p><hr><p>Tiled MM是一种进行矩阵乘法 内存友好的方法。</p><p>CUDA类型关键词</p><ul><li><code>__device__ __shared__</code> memory: shared; scope: block; lifetime: block</li><li><code>__device__</code> memory: global; scope: grid; lifetime: application</li><li><code>__device__ __constant__</code> memory: constant; scope: grid; lifetime: application</li></ul><hr><p>Race conditions:</p><p>CUDA中难以实现mutex，而且包含critical sections的代码在GPU上本来就运行得不好。</p><p>CUDA中有一些原子操作，可以在global或shared memory变量上操作</p><ul><li><code>int atomicInc(int *addr)</code>: 加一，返回旧值</li><li><code>int atomicAdd(int *addr, int val)</code>: 加val, 返回旧值</li><li><code>int atomicMax(int *addr, int val)</code>: 让*addr=max(*addr, val) 并返回旧值</li><li><code>int atomicExch(int *addr1, int val)</code>: set</li><li><code>int atomicCAS(int *addr, old, new)</code>: Compare and swap.<ul><li><code>if (*addr == old) *addr = new;</code></li></ul></li></ul></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/Lecture-Notes/" class="category-chain-item">Lecture Notes</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/C/" class="print-no-link">#C</a> <a href="/tags/Lecture-Notes/" class="print-no-link">#Lecture Notes</a> <a href="/tags/CUDA/" class="print-no-link">#CUDA</a></div></div><div class="license-box my-3"><div class="license-title"><div>[Lecture Notes] CMU 15-618 Parallel Computer Architecture &amp; Programming</div><div>https://www.billhu.us/2025/054_cmu_15618/</div></div><div class="license-meta"><div class="license-meta-item"><div>Author</div><div>Bill Hu</div></div><div class="license-meta-item license-meta-date"><div>Posted on</div><div>January 7, 2025</div></div><div class="license-meta-item"><div>Licensed under</div><div><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - Attribution"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/2025/056_cmu_14740/" title="[Lecture Notes] CMU 14-740 Fundamentals of Telecommunication Networks"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">[Lecture Notes] CMU 14-740 Fundamentals of Telecommunication Networks</span> <span class="visible-mobile">Previous</span></a></article><article class="post-next col-6"><a href="/2024/051-cmu-15513/" title="[Lecture Notes] CMU 15-513 Intro to Computer Systems"><span class="hidden-mobile">[Lecture Notes] CMU 15-513 Intro to Computer Systems</span> <span class="visible-mobile">Next</span> <i class="iconfont icon-arrowright"></i></a></article></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>Table of Contents</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">Search</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">Keyword</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <span>With </span><a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> <i class="iconfont icon-love"></i> <a href="/about" target="_blank" rel="nofollow noopener"><span>Bill Hu</span></a><div style="font-size:.85rem"><span id="timeDate">Loading days...</span> <span id="times">Loading time...</span><script src="/js/duration.min.js"></script></div></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t){var e=Fluid.plugins.typing,t=t.getElementById("subtitle");t&&e&&e(t.getAttribute("data-typed-text"))}((window,document))</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",function(){var t,o=jQuery("#toc");0!==o.length&&window.tocbot&&(t=jQuery("#board-ctn").offset().top,window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-t},CONFIG.toc)),0<o.find(".toc-list-item").length&&o.css("visibility","visible"),Fluid.events.registerRefreshCallback(function(){var t;"tocbot"in window&&(tocbot.refresh(),0!==(t=jQuery("#toc")).length)&&tocbot&&0<t.find(".toc-list-item").length&&t.css("visibility","visible")}))})</script><script src="https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n,o=[];for(n of(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","))o.push(".markdown-body > "+n.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback(function(){if("anchors"in window){anchors.removeAll();var n,o=[];for(n of(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","))o.push(".markdown-body > "+n.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}})})</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",function(){Fluid.plugins.fancyBox()})</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">Blog works best with JavaScript enabled</div></noscript></body></html>